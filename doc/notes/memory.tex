\documentclass{article}
\usepackage{alltt}
\usepackage[headheight=144pt,top=2in,left=1in,right=1in,bottom=1.6in]{geometry}
\usepackage{graphicx}

\setlength{\parskip}{0.6em}
\setlength{\parindent}{0pt}

\begin{document}

\section{Symbolic Translation}

Minimizing the number of execution paths to consider is an important
optimization in symbolic simulation.
%
When the symbolic simulator encounters a conditional branch on a indeterminate
symbolic value, the simulator will need to explore both execution paths.
%
This can lead to an explosion in the number of paths that the symbolic
simulator must travese if those executions encounter additional conditional
branches.

To minimize the number of execution paths, the LLVM simulator performs a
post-dominator-based analysis that identifies when divergent execution paths
can be rejoined into a single execution path.
%
A basic block $y$ is a \emph{strict post-dominator} of a basic block $x$ if $x
\neq y$ and all execution paths starting from $x$ reach $y$.
%
We say that $y$ is the \emph{immediate post-dominator} of $x$ if $y$ is
strictly post-dominates $x$, but does not strictly post-dominator any of $x's$
strict post-dominators.

In our path, each basic block that is the immediate post-dominator of another
basic block represents a potential merge point.
%
When execution diverges on a conditional branch, the simulator will run each
execution state separately and merge at the immediate post-dominator of the
branch.
%
If a node contains no other immediate post-dominators, then the merge will
occur when returning from the procedure.

To simplify the implementation, improve performance, and making debugging easier,
the symbolic simulator uses a two-phased approach for analyzing and symbolically
execution the program.

\begin{itemize}

 \item In the first phase, the symbolic simulator analyzes the LLVM IR for the
         program, and constructs an \emph{explictly symbolic program} that
         identifies potential branch and merge points with explicitly
         instructions.  Each immediate post-dominator has an associated
         \emph{merge frame} used to store paths that reach that merge frame.
         During execution, the symbolic simulator maintains a stack of merge
         frames.  When the symbolic simulator jumps to a block with a new
         post-dominator, the merge frame for the post-dominator is pushed 
         onto the stack.

 \item In the second phase, the symbolic simulator executes the symbolic
         program directly, and performs branching and merging based on
         the actual symbolic values.

\end{itemize}

To understand how this process works in practice, we will describe our approach
using the C code in Figure~\ref{figure:oddsum}.  This code contains a simple
program that returns the number of odd integers in an array.  When this
program is compiled with \texttt{clang}, it generates LLVM bytecode with the
control flow graph shown in the figure.

To symbolically simulate this code, the simulator first performs a
post-dominator analysis to construct the immediate post-dominator tree in
Figure~\ref{figure:symbolic}.  Each basic block is then transformed separately
from the concrete representation to the symbolic representation.  If a branch
is taken from a node to its immediate post-dominator then the execution path is
merged into the merge frame for the post-dominator.  To see a complex example,
the symbolic code for the for loop condition is given in the figure.

\begin{figure}[tb]
\begin{center}
\begin{tabular}{cc}
\begin{minipage}[b]{2.2in}
\begin{alltt}
int odd_sum(int* a, int l) \{
  int sum = 0;
  for (int i = 0; i < l; ++i) \{
    if (a[i] & 1) sum += 1;
  \}
  return sum;
\}



\end{alltt}
\end{minipage}
&
\includegraphics{cfg.odd_sum.pdf}
\end{tabular}
\end{center}
\caption{Source and CFG for \texttt{odd\_sum}}
  \label{figure:oddsum}
\end{figure}

\begin{figure}[tb]
\begin{center}
\begin{tabular}{cc}

\includegraphics{odd_sum.dominator.pdf}

&
\begin{minipage}[b]{3in}
\small
\begin{verbatim}
%for.cond.0:
  %tmp = load i32* %i, align 4
  %tmp1 = load i32* %l.addr, align 4
  %cmp = icmp ne i32 %tmp, %tmp1
  if (%cmp == 1) {
    setCurrentBlock %for.body.0
    pushPostDominatorFrame %for.cond.0
    pushPostDominatorFrame %for.inc.0
    pushPostDominatorFrame %if.end.0
  } else if (%cmp == 0) {
    setCurrentBlock %for.end.0
    mergePostDominator %for.end.0, true
    clearCurrentExecution
  } else {
    setCurrentBlock %for.cond.1
    pushPendingExecution %cmp == 0
    addPathConstraint %cmp == 1
    setCurrentBlock %for.body.0
    pushPostDominatorFrame %for.cond.0
    pushPostDominatorFrame %for.inc.0
    pushPostDominatorFrame %if.end.0
  }
%for.cond.1:
  setCurrentBlock %for.end.0
  mergePostDominator %for.end.0, true
  clearCurrentExecution
\end{verbatim}
\end{minipage}
\end{tabular}
\end{center}
\caption{Post-dominators and Symbolic Transformation of \texttt{odd\_sum}}
  \label{figure:symbolic}
\end{figure}

\section{LLVM Memory Model}

LLVM bytecode is a compiler intermediate representation designed to be
expressive enough to faithfully represent programs written in low-level
languages such as C.  As such, it does not enforce memory safety or type safety
as found in typed byte code representations such as the JVM and .Net
intermediate representation.  This can make designing a suitable memory model
more challenging as it must faithfully model the unsafe operations found in C
programs.

Some key properties that the symbolic memory model for LLVM must support are:
\begin{itemize}

  \item Support different pointer sizes, including 32 and 64-bit pointers.

  \item Allow pointers to:
    \begin{itemize}
      \item Global variables.
      \item Heap and stack allocated memory.
      \item Entry points to functions.
      \item Individual basic blocks within functions.

    \end{itemize}

  \item Allow casting between values with types of the same size--- including
          between code and data pointers.

  \item Support memory operations on symbolic pointer values.

  \item Allow memory to be allocated, initialized, and freed.

\end{itemize}

\subsection{Our Approch}

Due to the wide variety of applications and different memory operations
available, we believe that it is unlikely that a single memory model will
perform best on all programs.  For example, programs where concrete pointer
values are dominant will likely benefit from having a symbolic memory
representation that is similar to a concrete memory representation.  However,
applications where symbolic memory accesses occur regularly may need a
different approach.

We have designed the simulator to support multiple memory models, and implemented
the following two memory models in the course of this project:

\begin{itemize}

  \item The first model, called the \emph{bitblast} model, represents memory
           as a mapping from concrete addresses to symbolic values.  The map
           itself is stored as a binary tree.
           
   \begin{itemize}

     \item Internal nodes represent a contiguous block of memory where the
             number of bytes is a power of two.  The two node's children each
             represent one half of the memory in the block.  The number of bytes
             represented depends on the depth of the block.  For example, the
             root node represents all of the memory, and its two children
             represent the upper and lower halves of memory.

     \item Leaf nodes represent either completely unallocated chunks of memory,
             or an individual byte.  Individual bytes contain $10$ bit literals;
             two for representing whether the memory is allocated and initialized
             respectively, and $8$ for representing the value of the byte if it
             is initialized.

   \end{itemize}


  \item The second model, called the \emph{dag-based} model, represents memory
          as a symbolic term, stored as a dag, the initial memory state is a
          constant representing a completely unallocated state, and
          modifications to memory appear as operators that are applied the previous
          memory state.  There are operators for:
          \begin{itemize}

            \item Defining a chunk of memory to represent a function, and individual blocks with in the function
            \item Allocating new memory for storing data of any kind.
            \item Storing bytes into memory.
            \item Copying two regions of memory.
            \item Muxing two memories together.
            \item Pushing and popping stack frames.

          \end{itemize}
          %
          Reading a memory value requires traversing the dag structure to find the
          most recent write to that location, and may return a symbolic expression
          if there is no well-defined most recent write.  Results

          To further improve performance, the dag term is partially normalized
          as it is constructed.  Normalization steps include: merging multiple
          allocations and writes to adjacent or overlapping locations into a
          single node; moving allocations before writes to improve grouping;
          reordering writes and allocations to improve grouping; and removing
          writes or allocations after the memory is freed.

\end{itemize}

The bitblast model performs well on concrete memory accesses, but performance
degrades on symbolic memory accesses.  The dag-based model is very fast on all
memory writes, but performance of reads may be quite slow on large memories.
In addition, the dag-based memory model supports more symbolic operations than
the bitblast model.  For example, allocating a symbolic number of bytes is
supported by the dag-based model, but not by the bitblast model.

\end{document}
